#version 450

#extension GL_ARB_separate_shader_objects : enable
#extension GL_ARB_shading_language_420pack : enable
#extension GL_GOOGLE_include_directive : enable

#define USE_VELOCITY

#include "Common.h"

// Following color clamping to fix dis-occlusion, can lead to flickering in high luminosity values
// specially around for specular regions. This is managed by tone mapping those regions at a cost
// of reduced brightness of those regions. Can either use Luminance weighing or log weighing techniques.
vec4 AdjustHDRColor(vec3 color)
{
    if(g_Info.taaFlickerCorrectionMode == 1)    // Log Weighing
    {
        return vec4(log2_safe(color), 1.0);
    }
    else if(g_Info.taaFlickerCorrectionMode == 2) // Luminance Weighing
    {
        float luminance = ComputeLuminance(color);
        float luminanceWeight = 1.0 / (1.0 + luminance);
        // Tutorial suggests this but it is broken. 
        return vec4(color, 1.0f) * luminanceWeight;
        // However this seems more accurate
        //outColor = vec4(color, luminanceWeight);
    }
    else // None
    {
        return vec4(color, 1.0);
    }
}

// Fixes ghosting when the camera is translation-al static but is rotating around.
// We do this by checking for the current pixel in the history buffer and if found,
// we blend it with the current pixel
vec2 ComputeReprojectedUV(ivec2 in_xy)
{
    vec2 reprojUV = vec2(0.0);
    vec2 uv = vec2(float(in_xy.x)/DISPLAY_RESOLUTION_X, float(in_xy.y)/DISPLAY_RESOLUTION_Y);
//#ifdef USE_VELOCITY
    if(g_Info.taaUseMotionVectors == 1.0f)
    {
        vec2 velocityUV = texture(sampler2D(g_RT_SampledImages[SAMPLE_ROUGH_METAL_MOTION], g_LinearSampler), uv).zw;
        reprojUV = uv + velocityUV;
    }
//#else
    else
    {
        float z = texture(sampler2D(g_RT_SampledImages[SAMPLE_PRIMARY_DEPTH], g_LinearSampler), uv).x;
        float x = (uv.x * 2.0) - 1.0;
        float y = ((1.0 - uv.y) * 2.0) - 1.0;
        vec4 projPos = vec4(x,y,z,1.0);
        vec4 worldPos = g_Info.camInvViewProj * projPos;

        vec4 prePos = g_Info.camPreViewProj * worldPos;
        prePos.xyz /= prePos.w;
        reprojUV = (prePos.xy * vec2(0.5, -0.5)) + 0.5;
    }
//#endif
    return reprojUV;
}

// However, when the camera moves, surfaces that were previously occluded start showing up. 
// Since they do not exist in the history buffer, blending against them makes no sense. Hence
// the artifacts now show up as streaks. This is due to disocclusion.
// This is solved by color clamping. We do this by sampling
// 3x3 neighbors in the current frame and clamping the history value to these limits. But ideally
// we need to reject those values instead of clamping them. But clamping nonetheless gets the job done.
vec3 ColorClampPrevious(vec2 in_uv, vec3 preColor)
{
    vec3 minColor = vec3(9999.0);
    vec3 maxColor = vec3(-9999.0);
    for(int i = -1; i < 1; i++)
    {
        for(int j = -1; j < 1; j++)
        {
            vec2 uv = in_uv + vec2(float(i)/DISPLAY_RESOLUTION_X, float(j)/DISPLAY_RESOLUTION_Y);
            vec4 curColor = texture(sampler2D(g_RT_SampledImages[SAMPLE_PRIMARY_COLOR], g_LinearSampler), uv);
            curColor = AdjustHDRColor(curColor.xyz);
            minColor = min(minColor, curColor.xyz);
            maxColor = max(maxColor, curColor.xyz);
        }
    }
    return clamp(preColor, minColor, maxColor);
}

float FilterCubic(float x, float B, float C)
{
    float y = 0.0f;
    float x2 = x * x;
    float x3 = x * x * x;
    if(x < 1)
        y = (12 - 9 * B - 6 * C) * x3 + (-18 + 12 * B + 6 * C) * x2 + (6 - 2 * B);
    else if (x <= 2)
        y = (-B - 6 * C) * x3 + (6 * B + 30 * C) * x2 + (-12 * B - 48 * C) * x + (8 * B + 24 * C);

    return y / 6.0f;
}

float Filter(float x, float filterRadius, bool rescaleCubic)
{
    // Cubic filters naturually work in a [-2, 2] domain. For the resolve case we
    // want to rescale the filter so that it works in [-1, 1] instead
    float cubicX = rescaleCubic ? x * 2.0f : x;
    return FilterCubic(cubicX, 0, 0.5f);
}

vec3 SamplePreviousColor(vec2 reprojUV)
{
    if(g_Info.taaReprojectionFilter == 0) // Standard Filtering 
    {
        return texture(sampler2D(g_RT_SampledImages[SAMPLE_PREV_PRIMARY_COLOR], g_LinearSampler), reprojUV).xyz;
    }
    else // Catmull Rom
    {
        vec3 sum = vec3(0.0);
        float totalWeight = 0.0f;
        vec2 reprojXY = reprojUV * vec2(DISPLAY_RESOLUTION_X, DISPLAY_RESOLUTION_Y);
        // sampling total 16 neighbors
        for(int dy = -2; dy <= 1; dy++) // 4 neighbors
        {
            for(int dx = -2; dx <= 1; dx++) // 4 neighbors 
            {
                vec2 samplePos = reprojXY + vec2(dx, dy);
                vec2 sampleUV = samplePos / vec2(DISPLAY_RESOLUTION_X, DISPLAY_RESOLUTION_Y);
                vec3 reprojSample = texture(sampler2D(g_RT_SampledImages[SAMPLE_PREV_PRIMARY_COLOR], g_LinearSampler), sampleUV).xyz;

                vec2 sampleDist = abs(samplePos - reprojXY);
                float filterWeight = Filter(sampleDist.x, 1.0f, false) *
                                     Filter(sampleDist.y, 1.0f, false);

                float sampleLum = ComputeLuminance(reprojSample);
                filterWeight *= 1.0f / (1.0f + sampleLum);

                sum += reprojSample * filterWeight;
                totalWeight += filterWeight;
            }
        }

        return max(sum / totalWeight, 0.0f);
    }
}

// Resolve is lerp blend between the current color buffer with the previous color 
// buffer. This could help resolving some aliasing and the jittering process,
// but only work as long as the camera has not moved. However Ghosting occurs.
vec3 Resolve(vec2 uv, vec2 reprojUV)
{   
    // sample pixel color from current color buffer
    // Then apply inverse luminance or log weighing filtering
    vec4 curColor = texture(sampler2D(g_RT_SampledImages[SAMPLE_PRIMARY_COLOR], g_LinearSampler), uv);
    curColor = AdjustHDRColor(curColor.xyz);

    // sample pixel color from previous color buffer
    vec4 prevColor = vec4(SamplePreviousColor(reprojUV).xyz, 1.0);
    prevColor = AdjustHDRColor(prevColor.xyz);
    prevColor.xyz = ColorClampPrevious(uv, prevColor.xyz);

    // linear interpolate between current and previous colors based on a weight
    // tutorial hard-codes this to 0.1, but I ll pass this as TAA_Resolve_Weight
    if(g_Info.taaFlickerCorrectionMode == 0) // None
    {
        return mix(curColor.xyz, prevColor.xyz, g_Info.taaResolveWeight);
    }
    else
    {
        float curWeight = (1.0 - g_Info.taaResolveWeight) * curColor.a;
        float prevWeight = (g_Info.taaResolveWeight) * prevColor.a;

        vec3 resColor = (curColor.xyz * curWeight) + (prevColor.xyz * prevWeight);
        resColor /= (curWeight + prevWeight);

        if(g_Info.taaFlickerCorrectionMode == 1) // Log Weighing
        {
            resColor = exp(resColor);
        }
        return resColor;
    }
}

layout (local_size_x = THREAD_GROUP_SIZE_X, local_size_y = THREAD_GROUP_SIZE_Y) in;
void main()
{
    vec2 uv = vec2(float(gl_GlobalInvocationID.x)/DISPLAY_RESOLUTION_X, float(gl_GlobalInvocationID.y)/DISPLAY_RESOLUTION_Y);

    vec2 reprojectedUV = ComputeReprojectedUV(ivec2(gl_GlobalInvocationID.xy));
    
    vec3 finalColor = Resolve(uv, reprojectedUV);
 
    imageStore(g_RT_StorageImages[STORE_PRIMARY_COLOR], ivec2(gl_GlobalInvocationID.xy), vec4(finalColor, 1.0));
}

