#version 460

#extension GL_ARB_separate_shader_objects : enable
#extension GL_ARB_shading_language_420pack : enable
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_nonuniform_qualifier : require

#include "Common.h"
#include "MeshCommon.h"
#include "RayTracingCommon.h"

// Format is R16G16B16A16. Hence 16 bits per channel to represent per light's
// shadow. At the moment, the only supported light count that contribute to
// shadows is 4. We might later optimize this by reducing the precision and
// resolution per shadow depending on some research and experimentation 
// R16[Light_0 shadow] G16[Light_1 shadow] B16[Light_2 shadow] A16[Light_3 shadow]
layout (local_size_x = THREAD_GROUP_SIZE_X, local_size_y = THREAD_GROUP_SIZE_Y) in;
void main()
{
	// the the depth value of the fragment in NDC is calculated and 
	// checked if it is within the far plane at 1.0. If it is, compute 
	// the shadow
	vec4 shadowsOut = vec4(0);

	ivec2 xy = ivec2(gl_GlobalInvocationID.xy);
	vec2 sampleUV = vec2(gl_GlobalInvocationID.xy + 0.5) / vec2(RENDER_RESOLUTION_X, RENDER_RESOLUTION_Y);
	float sampleDepth = texture(sampler2D(g_RT_SampledImages[SAMPLE_PRIMARY_DEPTH], g_NearestSampler), sampleUV).x;
	vec4 fragPosVS = GetPositionfromDepth(sampleUV, sampleDepth);
		
	uint seed = genSeed(uint(gl_GlobalInvocationID.x + gl_GlobalInvocationID.y * gl_WorkGroupID.x), g_Info.frameCount, 16);
	
	// Sampling previous frame's shadow values for this position
	// Since we are accumulating the shadows over frame, we do
	// not maintain a previous shadow buffer, instead read and
	// update the Shadow Texture
	shadowsOut = imageLoad(g_RT_StorageImages[STORE_RT_SHADOW_TEMPORAL_ACC], xy).xyzw;    
	vec4 fragPosWS = g_Info.invCamView * fragPosVS;
	for(uint i = 0; i < g_lights.count; i++)
	{	
		Light light = g_lights.lights[i];
		uint lightType = light.type_castShadow >> 16;
		uint castShadow = light.type_castShadow - (lightType << 16);
			if(castShadow == 1)
		{
			float curShadow = 0.0;				
			if(lightType == DIRECTIONAL_LIGHT_TYPE)
			{
				vec4 LDirWS = vec4(light.vector3[0], light.vector3[1], light.vector3[2], 0.0f);
				if(light.coneAngle > 0.0)
				{
					LDirWS.xyz = getConeSample(seed, LDirWS.xyz, light.coneAngle);
				}					
				curShadow = 1.0 - TraceRay(fragPosWS.xyz, LDirWS.xyz, 1e3);
			}
			else if (lightType == POINT_LIGHT_TYPE)
			{
				// The light position is stored in World space
				// The light intensity is in View Space. Hence we 
				// compute the distance between the light and position
				// in view space and ensure it is less than the light's
				// intensity.
				vec4 LPosWS = vec4(light.vector3[0], light.vector3[1], light.vector3[2], 1.0f);
				vec3 LDirVS = ((g_Info.camView * LPosWS) - fragPosVS).xyz;
				float distVS = length(LDirVS);
				float attenuation = max(0.0f, light.intensity - distVS);
				// The ray tracing needs to happen in world space since
				// the BVH is built in world space.
				vec3 LDirWS = LPosWS.xyz - fragPosWS.xyz;
				float distWS = length(LDirWS);
				LDirWS = normalize(LDirWS);
				if(attenuation > 0.0)
				{
					if(light.coneAngle > 0.0)
					{
						LDirWS.xyz = getConeSample(seed, LDirWS.xyz, light.coneAngle);
					}						
					curShadow = 1.0 - TraceRay(fragPosWS.xyz, LDirWS.xyz, distWS);	
				}
			}
			shadowsOut[i] = mix(shadowsOut[i], curShadow, g_Info.shadowTempAccumWeight);
		}
	}
	
   	imageStore(g_RT_StorageImages[STORE_RT_SHADOW_TEMPORAL_ACC], xy, shadowsOut); 
}	